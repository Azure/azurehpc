apiVersion: v1
data:
  kernel-monitor.json: |
    {
        "plugin": "kmsg",
        "logPath": "/dev/kmsg",
        "lookback": "5m",
        "bufferSize": 10,
        "source": "kernel-monitor",
        "conditions": [
            {
                "type": "KernelDeadlock",
                "reason": "KernelHasNoDeadlock",
                "message": "kernel has no deadlock"
            },
            {
                "type": "ReadonlyFilesystem",
                "reason": "FilesystemIsNotReadOnly",
                "message": "Filesystem is not read-only"
            }
        ],
        "rules": [
            {
                "type": "temporary",
                "reason": "OOMKilling",
                "pattern": "Kill process \\d+ (.+) score \\d+ or sacrifice child\\nKilled process \\d+ (.+) total-vm:\\d+kB, anon-rss:\\d+kB, file-rss:\\d+kB.*"
            },
            {
                "type": "temporary",
                "reason": "TaskHung",
                "pattern": "task \\S+:\\w+ blocked for more than \\w+ seconds\\."
            },
            {
                "type": "temporary",
                "reason": "UnregisterNetDevice",
                "pattern": "unregister_netdevice: waiting for \\w+ to become free. Usage count = \\d+"
            },
            {
                "type": "temporary",
                "reason": "KernelOops",
                "pattern": "BUG: unable to handle kernel NULL pointer dereference at .*"
            },
            {
                "type": "temporary",
                "reason": "KernelOops",
                "pattern": "divide error: 0000 \\[#\\d+\\] SMP"
            },
            {
                        "type": "temporary",
                        "reason": "MemoryReadError",
                        "pattern": "CE memory read error .*"
            },
            {
                "type": "permanent",
                "condition": "KernelDeadlock",
                "reason": "DockerHung",
                "pattern": "task docker:\\w+ blocked for more than \\w+ seconds\\."
            },
            {
                "type": "permanent",
                "condition": "ReadonlyFilesystem",
                "reason": "FilesystemIsReadOnly",
                "pattern": "Remounting filesystem read-only"
            }
        ]
    }
  docker-monitor.json: |
    {
        "plugin": "journald",
        "pluginConfig": {
            "source": "dockerd"
        },
        "logPath": "/var/log/journal",
        "lookback": "5m",
        "bufferSize": 10,
        "source": "docker-monitor",
        "conditions": [],
        "rules": [
            {
                "type": "temporary",
                "reason": "CorruptDockerImage",
                "pattern": "Error trying v2 registry: failed to register layer: rename /var/lib/docker/image/(.+) /var/lib/docker/image/(.+): directory not empty.*"
            }
        ]
    }
  custom-plugin-monitor.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
        "invoke_interval": "30s",
        "timeout": "15s",
        "max_output_length": 80,
        "concurrency": 3,
        "enable_message_change_based_condition_update": false
      },
      "source": "ntp-custom-plugin-monitor",
      "metricsReporting": true,
      "conditions": [
        {
          "type": "NTPProblem",
          "reason": "NTPIsUp",
          "message": "ntp service is up"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "NTPIsDown",
          "path": "./config/plugin/check_ntp.sh",
          "timeout": "10s"
        },
        {
          "type": "permanent",
          "condition": "NTPProblem",
          "reason": "NTPIsDown",
          "path": "./config/plugin/check_ntp.sh",
          "timeout": "10s"
        }
      ]
    }
  check_ntp.sh: |
    #!/bin/bash

    # This plugin checks if the ntp service is running under systemd.
    # NOTE: This is only an example for systemd services.

    readonly OK=0
    readonly NONOK=1
    readonly UNKNOWN=2

    readonly SERVICE='ntp.service'

    # Check systemd cmd present
    if ! command -v systemctl >/dev/null; then
      echo "Could not find 'systemctl' - require systemd"
      exit $UNKNOWN
    fi

    # Return success if service active (i.e. running)
    if systemctl -q is-active "$SERVICE"; then
      echo "$SERVICE is running"
      exit $OK
    else
    # Does not differentiate stopped/failed service from non-existent
      echo "$SERVICE is not running"
      exit $NONOK
    fi
  custom-plugin-gpu-count.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
      "invoke_interval": "30s",
      "timeout": "20s",
      "max_output_length": 80,
      "concurrency": 3,
      "enable_message_change_based_condition_update": false
      },
      "source": "custom-plugin-gpu-count",
      "metricsReporting": false,
      "conditions": [
        {
          "type": "GpuCount",
          "reason": "GpuCountGood",
          "message": "GPU count is correct"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "GpuCountBad",
          "path": "./config/plugin/check_gpu_count.sh",
          "timeout": "5s"
        },
        {
          "type": "permanent",
          "condition": "GpuCount",
          "reason": "GpuCountBad",
          "path": "./config/plugin/check_gpu_count.sh",
          "timeout": "5s"
        }
      ]
    }
  check_gpu_count.sh: |
    #!/bin/bash

    # This plugin checks if is the VM has the correct number of GPU's

    readonly OK=0
    readonly NONOK=1
    readonly UNKNOWN=2

    readonly EXPECTED_NUM_GPU=8
    readonly GPU_TYPE="nvidia"


    if [ "$GPU_TYPE" == "rocm" ]; then
       gpu_count=$(rocm-smi -l | grep 'GPU' | wc -l)
    else
       gpu_count=$(nvidia-smi --list-gpus | wc -l)
    fi

    if [ "$gpu_count" -ne "$EXPECTED_NUM_GPU" ]; then
       echo "Expected to see $EXPECTED_NUM_GPU but found $gpu_count. FaultCode: NHC2009"
       exit $NONOK
    else
       echo "Expected $EXPECTED_NUM_GPU and found $gpu_count"
       exit $OK
    fi
  custom-plugin-gpu-nvlink.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
      "invoke_interval": "60s",
      "timeout": "35s",
      "max_output_length": 80,
      "concurrency": 3,
      "enable_message_change_based_condition_update": false
      },
      "source": "custom-plugin-gpu-nvlink",
      "metricsReporting": false,
      "conditions": [
        {
          "type": "GpuNvlink",
          "reason": "GpuNvlinkGood",
          "message": "GPU NVlink is ok"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "GpuNvlinkBad",
          "path": "./config/plugin/check_gpu_nvlink.sh",
          "timeout": "20s"
        },
        {
          "type": "permanent",
          "condition": "GpuNvlink",
          "reason": "GpuNvlinkBad",
          "path": "./config/plugin/check_gpu_nvlink.sh",
          "timeout": "20s"
        }
      ]
    }
  check_gpu_nvlink.sh: |
    #!/bin/bash
    # This plugin checks if is the GPU NVlink is working correctly.

    readonly OK=0
    readonly NONOK=1
    readonly UNKNOWN=2

    readonly EXPECTED_NUM_GPU=8


    # Check if nvlink is enabled
    num_gpus=$EXPECTED_NUM_GPU

    nvlink_status=$(nvidia-smi nvlink --status)
    if [ $? -ne 0 ]; then
       echo "Failed to get NVLINK status with error code $?. FaultCode: NHC2016"
                exit $NONOK
    fi
    if [ -z "$nvlink_status" ]; then
       echo "NVLINK is not enabled"
       exit $OK
    fi
    for ((i=0; i<num_gpus; i++)); do
        gpu_id=$i
    # Run nvlink command
        nvlink_output=$(nvidia-smi nvlink -s -i $gpu_id)
        if [ $? -ne 0 ]; then
           echo "Failed to get NVLINK status with error code $?. FaultCode: NHC2016"
           exit $NONOK
        fi
     # Check for inactive links
        if [[ $nvlink_output == *"inactive"* ]]; then
     # Extract and display the information about inactive links
           inactive_links=$(echo "$nvlink_output" | grep "Link" | grep "<inactive>" | sed 's/Link \([0-9]*\): <inactive>/Link \1: Inactive/')
           echo "GPU $gpu_id has nvlinks inactive: $inactive_links. FaultCode: NHC2016"
           exit 1
        elif [[ $nvlink_output == *"all links are inActive"* ]]; then
             echo "GPU $gpu_id has all nvlinks inactive"
             exit 1
        else
             echo "GPU $gpu_id has all nvlinks active."
             exit $OK
        fi
        echo "NVLink is enabled and GPU $gpu_id has all nvlinks active"
        exit $OK
    done

    exit 0
  custom-plugin-gpu-xid.json: |
    {
      "plugin": "custom",
      "pluginConfig": {
      "invoke_interval": "60s",
      "timeout": "35s",
      "max_output_length": 80,
      "concurrency": 3,
      "enable_message_change_based_condition_update": false
      },
      "source": "custom-plugin-gpu-xid",
      "metricsReporting": false,
      "conditions": [
        {
          "type": "GpuXid",
          "reason": "GpuXidGood",
          "message": "GPU XID is ok"
        }
      ],
      "rules": [
        {
          "type": "temporary",
          "reason": "GpuXidBad",
          "path": "./config/plugin/check_gpu_xid.sh",
          "timeout": "20s"
        },
        {
          "type": "permanent",
          "condition": "GpuXid",
          "reason": "GpuXidBad",
          "path": "./config/plugin/check_gpu_xid.sh",
          "timeout": "20s"
        }
      ]
    }
  check_gpu_xid.sh: |
    #!/bin/bash
    # This plugin checks GPU XID errors
    readonly OK=0
    readonly NONOK=1
    readonly UNKNOWN=2

    # time threshold in hours
    readonly time_threshold=2
    readonly logfile="/var/log/azakslog"
    readonly kernel_log="var/log/syslog"
    readonly XID_EC="48 56 57 58 62 63 64 65 68 69 73 74 79 80 81 92 119 120"
    readonly GPU_XID_TEST="GPU Xid errors detected"


    if [[ ! -f $kernel_log ]]; then
       echo "$kernel_log not found. Skipping GPU Xid error test."
       exit $NONOK
    fi

    # check for any xid errors
    grep -q "Xid" $kernel_log
    RC=$?
    if [ $RC == 0 ]; then
       for XID in $XID_EC; do
           xid_found_line=$(grep "Xid.*: $XID," $kernel_log  | tail -n 1)
           if [ "$xid_found_line" != "" ]; then
              logXid=$(echo "$xid_found_line" | awk -F ',' '{print $1}' )
              logMsg="Found XID: $logXid"
              log_date="$(echo "$logXid" | awk '{print $1, $2, $3}') $(date +"%Y")"
              log_date=$(date -d "$log_date" +"%s")
              current_ts=$(date +"%s")
              diff=$(( (current_ts - log_date) / 3600 ))

              if [ "$diff" -le $time_threshold ]; then
    # check if the XID has been reported in the log before
                 if grep -qF "$logMsg" "$logfile"; then
                    echo "This XID has been reported before: $logXid."
                 else
                    echo "$logMsg" >> $logfile
                    echo "$GPU_XID_TEST: $xid_found_line. FaultCode: NHC2001"
                    exit $NONOK
                 fi
              else
                echo "Xid older than $time_threshold hours: $diff hours. Skipping this XID error: $logXid." >> $logfile
              fi

           else
             echo "No GPU Xid $XID error found in kernel log"
             exit $OK
           fi
      done
    fi

    echo "GPU XID error check passed."
    exit $OK
kind: ConfigMap
metadata:
  name: node-problem-detector-config
  namespace: kube-system
